{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e96b9416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns:\n",
      "['Date', 'AU', 'YEAR', 'QUARTER', 'US RGDP Annual Forecast', 'date', 'GB BN_SURVEY_AVERAGE', 'Date.1', 'CH YoY Growth', 'Date.2', 'JP YoY Growth', 'Date.3', 'EU YoY Growth']\n",
      "        Date        AU     GB        CH        JP        EU        US\n",
      "0 2025-10-01  0.038000  0.025  0.012846  0.010747  0.013505  0.015632\n",
      "1 2025-09-01  0.032000  0.025  0.012846  0.010747  0.013505  0.014502\n",
      "2 2025-08-01  0.032000  0.025  0.012846  0.010747  0.013505  0.014502\n",
      "3 2025-07-01  0.032000  0.025  0.012846  0.010747  0.013505  0.014502\n",
      "4 2025-06-01  0.021000  0.025  0.024395  0.019764  0.015220  0.013453\n",
      "5 2025-05-01  0.021000  0.025  0.024395  0.019764  0.015220  0.013453\n",
      "6 2025-04-01  0.021000  0.025  0.024395  0.019764  0.015220  0.013453\n",
      "7 2025-03-01  0.024018  0.016  0.016688  0.018356  0.016217  0.021749\n",
      "8 2025-02-01  0.024018  0.016  0.016688  0.018356  0.016217  0.021749\n",
      "9 2025-01-01  0.024018  0.016  0.016688  0.018356  0.016217  0.021749\n"
     ]
    }
   ],
   "source": [
    "### Dont need this code anymore, but I want it!\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# ---- 1. Read the original Excel file ----\n",
    "file_in = r\"C:/Users/Sedl√°ƒçek/Documents/UZH/PMP/Macro_momentum/PMP_December_8/Data/GDP_forecast.xlsx\"\n",
    "df = pd.read_excel(file_in)\n",
    "\n",
    "# Clean up column names (remove extra spaces etc.)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "print(\"Original columns:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ---- 2. Define which date/value column belongs to which region (except US) ----\n",
    "region_map = {\n",
    "    \"AU\": {\"date_col\": \"Date\",    \"value_col\": \"AU\"},\n",
    "    \"GB\": {\"date_col\": \"Date.1\",  \"value_col\": \"GB BN_SURVEY_AVERAGE\"},\n",
    "    \"CH\": {\"date_col\": \"Date.2\",  \"value_col\": \"CH YoY Growth\"},\n",
    "    \"JP\": {\"date_col\": \"Date.3\",  \"value_col\": \"JP YoY Growth\"},\n",
    "    \"EU\": {\"date_col\": \"Date.3\",  \"value_col\": \"EU YoY Growth\"},  # same dates as JP\n",
    "}\n",
    "\n",
    "# Sanity check that the columns exist\n",
    "for r, info in region_map.items():\n",
    "    for c in (info[\"date_col\"], info[\"value_col\"]):\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Column '{c}' for region {r} not found in DataFrame!\")\n",
    "\n",
    "# ---- 3. Helper to build tidy DataFrame for one region (non-US) ----\n",
    "def make_region_df(df, region, date_col, value_col):\n",
    "    sub = df[[date_col, value_col]].copy()\n",
    "    sub.columns = [\"Date\", region]\n",
    "\n",
    "    # Parse dates\n",
    "    sub[\"Date\"] = pd.to_datetime(sub[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "    # Convert values to numeric (no extra percent scaling!)\n",
    "    sub[region] = pd.to_numeric(sub[region], errors=\"coerce\")\n",
    "\n",
    "    # Drop rows without dates\n",
    "    sub = sub.dropna(subset=[\"Date\"])\n",
    "    return sub\n",
    "\n",
    "# ---- 4. Build region DataFrames for AU, GB, CH, JP, EU ----\n",
    "region_dfs = []\n",
    "for region, info in region_map.items():\n",
    "    r_df = make_region_df(\n",
    "        df,\n",
    "        region=region,\n",
    "        date_col=info[\"date_col\"],\n",
    "        value_col=info[\"value_col\"],\n",
    "    )\n",
    "    region_dfs.append(r_df)\n",
    "\n",
    "# ---- 5. Build US DataFrame from YEAR + QUARTER ----\n",
    "us = df[[\"YEAR\", \"QUARTER\", \"US RGDP Annual Forecast\"]].copy()\n",
    "\n",
    "# Drop rows without year/quarter/value\n",
    "us = us.dropna(subset=[\"YEAR\", \"QUARTER\", \"US RGDP Annual Forecast\"])\n",
    "\n",
    "# Ensure integers for YEAR/QUARTER\n",
    "us[\"YEAR\"] = us[\"YEAR\"].astype(int)\n",
    "us[\"QUARTER\"] = us[\"QUARTER\"].astype(int)\n",
    "\n",
    "# Map quarter to first month of quarter: Q1‚Üí1, Q2‚Üí4, Q3‚Üí7, Q4‚Üí10\n",
    "us[\"month\"] = (us[\"QUARTER\"] - 1) * 3 + 1\n",
    "\n",
    "# Build a Date column at the start of the quarter\n",
    "us[\"Date\"] = pd.to_datetime(\n",
    "    dict(year=us[\"YEAR\"], month=us[\"month\"], day=1),\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only Date and value, rename value column to 'US'\n",
    "us = us[[\"Date\", \"US RGDP Annual Forecast\"]].rename(\n",
    "    columns={\"US RGDP Annual Forecast\": \"US\"}\n",
    ")\n",
    "\n",
    "# Convert US values to numeric\n",
    "us[\"US\"] = pd.to_numeric(us[\"US\"], errors=\"coerce\")\n",
    "us = us.dropna(subset=[\"Date\"])\n",
    "\n",
    "region_dfs.append(us)\n",
    "\n",
    "# ---- 6. Merge all regions on Date (outer join) ----\n",
    "merged = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=\"Date\", how=\"outer\"),\n",
    "    region_dfs\n",
    ")\n",
    "\n",
    "# ---- 7. Sort by date and place on a monthly grid, forward-fill ----\n",
    "merged = merged.sort_values(\"Date\")\n",
    "\n",
    "# Monthly frequency: month-start\n",
    "monthly = (\n",
    "    merged.set_index(\"Date\")\n",
    "          .resample(\"MS\")     # Month Start\n",
    "          .asfreq()\n",
    "          .sort_index()\n",
    ")\n",
    "\n",
    "# Forward-fill missing months for all regions\n",
    "monthly = monthly.ffill()\n",
    "\n",
    "# Back to a regular column index\n",
    "monthly = monthly.reset_index()\n",
    "\n",
    "# Divide US, AU, GB by 100\n",
    "cols_to_divide = [\"US\", \"AU\", \"GB\"]\n",
    "\n",
    "for col in cols_to_divide:\n",
    "    if col in monthly.columns:\n",
    "        monthly[col] = monthly[col] / 100.0\n",
    "\n",
    "GDP_forecast =monthly\n",
    "\n",
    "\n",
    "# ---- 7. Sort by date and place on a monthly grid, forward-fill ----\n",
    "merged = merged.sort_values(\"Date\")\n",
    "\n",
    "# Monthly frequency: month-start\n",
    "monthly = (\n",
    "    merged.set_index(\"Date\")\n",
    "          .resample(\"MS\")     # Month Start\n",
    "          .asfreq()\n",
    "          .sort_index()\n",
    ")\n",
    "\n",
    "# Forward-fill missing months for all regions\n",
    "monthly = monthly.ffill()\n",
    "\n",
    "# Back to a regular column index\n",
    "monthly = monthly.reset_index()\n",
    "\n",
    "# Divide US, AU, GB by 100\n",
    "cols_to_divide = [\"US\", \"AU\", \"GB\"]\n",
    "for col in cols_to_divide:\n",
    "    if col in monthly.columns:\n",
    "        monthly[col] = monthly[col] / 100.0\n",
    "\n",
    "# (Optional) Drop rows where ALL non-US regions are still NaN\n",
    "non_us_regions = [\"AU\", \"GB\", \"CH\", \"JP\", \"EU\"]\n",
    "monthly = monthly.dropna(subset=non_us_regions, how=\"all\")\n",
    "\n",
    "# üîΩ Sort so that the newest date is first\n",
    "monthly = monthly.sort_values(\"Date\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "GDPforecast = monthly\n",
    "\n",
    "print(GDPforecast.head(10))\n",
    "\n",
    "out_path = r\"C:/Users/Sedl√°ƒçek/Documents/UZH/PMP/Macro_momentum/PMP_December_8/Data/GDP_forecasts.csv\"\n",
    "GDPforecast.to_csv(out_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d18f5c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns:\n",
      "['YEAR', 'QUARTER', 'US Forecast', 'observation_date', 'UK', 'CH', 'JP', 'AU', 'EU']\n",
      "Done. Rearranged table saved to: INF_forecast_rearranged.xlsx\n",
      "          Date        GB        CH        JP     AU        EU      US\n",
      "0   2025-10-01  0.038000  0.000100  0.030000  0.038  0.020789  0.0288\n",
      "1   2025-09-01  0.041000  0.002000  0.029000  0.032  0.022124  0.0279\n",
      "2   2025-08-01  0.041000  0.002000  0.027000  0.032  0.020289  0.0279\n",
      "3   2025-07-01  0.042000  0.002000  0.031000  0.032  0.020079  0.0279\n",
      "4   2025-06-01  0.041000  0.001000  0.033000  0.021  0.019676  0.0317\n",
      "..         ...       ...       ...       ...    ...       ...     ...\n",
      "665 1970-05-01  0.060836  0.031368  0.072456    NaN       NaN     NaN\n",
      "666 1970-04-01  0.056188  0.025928  0.076836    NaN       NaN     NaN\n",
      "667 1970-03-01  0.051420  0.024992  0.077171    NaN       NaN     NaN\n",
      "668 1970-02-01  0.049307  0.021236  0.077513    NaN       NaN     NaN\n",
      "669 1970-01-01  0.049574  0.023134  0.077513    NaN       NaN     NaN\n",
      "\n",
      "[670 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# ---- 1. Read the Inflation forecast file ----\n",
    "file_in = r\"C:/Users/Sedl√°ƒçek/Documents/UZH/PMP/Macro_momentum/PMP_December_8/Data/INF_forecast.xlsx\"\n",
    "df = pd.read_excel(file_in)\n",
    "\n",
    "# Clean up column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "print(\"Original columns:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ---- 2. Region mapping for non-US (they all use observation_date) ----\n",
    "region_map = {\n",
    "    \"UK\": {\"date_col\": \"observation_date\", \"value_col\": \"UK\"},\n",
    "    \"CH\": {\"date_col\": \"observation_date\", \"value_col\": \"CH\"},\n",
    "    \"JP\": {\"date_col\": \"observation_date\", \"value_col\": \"JP\"},\n",
    "    \"AU\": {\"date_col\": \"observation_date\", \"value_col\": \"AU\"},\n",
    "    \"EU\": {\"date_col\": \"observation_date\", \"value_col\": \"EU\"},\n",
    "}\n",
    "\n",
    "# Sanity check that the columns exist\n",
    "for r, info in region_map.items():\n",
    "    for c in (info[\"date_col\"], info[\"value_col\"]):\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Column '{c}' for region {r} not found in DataFrame!\")\n",
    "\n",
    "# ---- 3. Helper: build tidy DataFrame for one region (non-US) ----\n",
    "def make_region_df(df, region, date_col, value_col):\n",
    "    sub = df[[date_col, value_col]].copy()\n",
    "    sub.columns = [\"Date\", region]\n",
    "\n",
    "    # Parse dates\n",
    "    sub[\"Date\"] = pd.to_datetime(sub[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "    # Values are already in percentages; keep as-is (no division by 100 here)\n",
    "    sub[region] = pd.to_numeric(sub[region], errors=\"coerce\")\n",
    "\n",
    "    # Drop rows without dates\n",
    "    sub = sub.dropna(subset=[\"Date\"])\n",
    "    return sub\n",
    "\n",
    "# ---- 4. Build DataFrames for UK, CH, JP, AU, EU ----\n",
    "region_dfs = []\n",
    "for region, info in region_map.items():\n",
    "    r_df = make_region_df(\n",
    "        df,\n",
    "        region=region,\n",
    "        date_col=info[\"date_col\"],\n",
    "        value_col=info[\"value_col\"],\n",
    "    )\n",
    "    region_dfs.append(r_df)\n",
    "\n",
    "# ---- 5. Build US DataFrame from YEAR + QUARTER ----\n",
    "us = df[[\"YEAR\", \"QUARTER\", \"US Forecast\"]].copy()\n",
    "\n",
    "# Remove rows missing any of these\n",
    "us = us.dropna(subset=[\"YEAR\", \"QUARTER\", \"US Forecast\"])\n",
    "\n",
    "# Ensure integers for YEAR/QUARTER\n",
    "us[\"YEAR\"] = us[\"YEAR\"].astype(int)\n",
    "us[\"QUARTER\"] = us[\"QUARTER\"].astype(int)\n",
    "\n",
    "# Map quarter to first month of quarter: Q1‚Üí1, Q2‚Üí4, Q3‚Üí7, Q4‚Üí10\n",
    "us[\"month\"] = (us[\"QUARTER\"] - 1) * 3 + 1\n",
    "\n",
    "# Construct Date as first day of quarter\n",
    "us[\"Date\"] = pd.to_datetime(\n",
    "    dict(year=us[\"YEAR\"], month=us[\"month\"], day=1),\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Keep only Date and value, rename value column to 'US'\n",
    "us = us[[\"Date\", \"US Forecast\"]].rename(columns={\"US Forecast\": \"US\"})\n",
    "\n",
    "# Values already in percentages; keep as-is\n",
    "us[\"US\"] = pd.to_numeric(us[\"US\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows without dates\n",
    "us = us.dropna(subset=[\"Date\"])\n",
    "\n",
    "region_dfs.append(us)\n",
    "\n",
    "# ---- 6. Merge all regions on Date (outer join) ----\n",
    "merged = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=\"Date\", how=\"outer\"),\n",
    "    region_dfs\n",
    ")\n",
    "\n",
    "# ---- 7. Sort by date, resample monthly, forward-fill ----\n",
    "merged = merged.sort_values(\"Date\")\n",
    "\n",
    "# Put on a monthly grid (Month Start)\n",
    "monthly = (\n",
    "    merged.set_index(\"Date\")\n",
    "          .resample(\"MS\")   # Month Start\n",
    "          .asfreq()\n",
    "          .sort_index()\n",
    ")\n",
    "\n",
    "# Forward-fill missing months for all regions\n",
    "monthly = monthly.ffill()\n",
    "\n",
    "# Back to normal columns\n",
    "monthly = monthly.reset_index()\n",
    "\n",
    "# ---- 8. Save the rearranged table ----\n",
    "file_out = \"INF_forecast_rearranged.xlsx\"\n",
    "#monthly.to_excel(file_out, index=False)\n",
    "\n",
    "# Divide US, AU, GB by 100\n",
    "cols_to_divide = ['UK', 'CH', 'JP', 'AU', 'EU', 'US']\n",
    "\n",
    "for col in cols_to_divide:\n",
    "    if col in monthly.columns:\n",
    "        monthly[col] = monthly[col] / 100.0\n",
    "\n",
    "INFforecast = monthly\n",
    "INFforecast.rename(columns={'UK': 'GB'}, inplace=True)\n",
    "\n",
    "INFforecast = INFforecast.sort_values(\"Date\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Done. Rearranged table saved to:\", file_out)\n",
    "print(INFforecast)\n",
    "\n",
    "out_path = r\"C:/Users/Sedl√°ƒçek/Documents/UZH/PMP/Macro_momentum/PMP_December_8/Data/Inflation_forecasts.csv\"\n",
    "INFforecast.to_csv(out_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22d51c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date        AU     GB        CH        JP        EU        US\n",
      "0   2025-10-01  0.038000  0.025  0.012846  0.010747  0.013505  0.015632\n",
      "1   2025-09-01  0.032000  0.025  0.012846  0.010747  0.013505  0.014502\n",
      "2   2025-08-01  0.032000  0.025  0.012846  0.010747  0.013505  0.014502\n",
      "3   2025-07-01  0.032000  0.025  0.012846  0.010747  0.013505  0.014502\n",
      "4   2025-06-01  0.021000  0.025  0.024395  0.019764  0.015220  0.013453\n",
      "..         ...       ...    ...       ...       ...       ...       ...\n",
      "659 1970-11-01  0.052632    NaN       NaN       NaN       NaN  0.029943\n",
      "660 1970-10-01  0.052632    NaN       NaN       NaN       NaN  0.029943\n",
      "661 1970-09-01  0.031579    NaN       NaN       NaN       NaN  0.029362\n",
      "662 1970-08-01  0.031579    NaN       NaN       NaN       NaN  0.029362\n",
      "663 1970-07-01  0.031579    NaN       NaN       NaN       NaN  0.029362\n",
      "\n",
      "[664 rows x 7 columns]\n",
      "          Date        GB        CH        JP     AU        EU      US\n",
      "0   2025-10-01  0.038000  0.000100  0.030000  0.038  0.020789  0.0288\n",
      "1   2025-09-01  0.041000  0.002000  0.029000  0.032  0.022124  0.0279\n",
      "2   2025-08-01  0.041000  0.002000  0.027000  0.032  0.020289  0.0279\n",
      "3   2025-07-01  0.042000  0.002000  0.031000  0.032  0.020079  0.0279\n",
      "4   2025-06-01  0.041000  0.001000  0.033000  0.021  0.019676  0.0317\n",
      "..         ...       ...       ...       ...    ...       ...     ...\n",
      "665 1970-05-01  0.060836  0.031368  0.072456    NaN       NaN     NaN\n",
      "666 1970-04-01  0.056188  0.025928  0.076836    NaN       NaN     NaN\n",
      "667 1970-03-01  0.051420  0.024992  0.077171    NaN       NaN     NaN\n",
      "668 1970-02-01  0.049307  0.021236  0.077513    NaN       NaN     NaN\n",
      "669 1970-01-01  0.049574  0.023134  0.077513    NaN       NaN     NaN\n",
      "\n",
      "[670 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(GDPforecast)\n",
    "print(INFforecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd7f87f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date        AU        GB        CH        JP        EU        US\n",
      "0  2025-10-01  0.013753  0.012755 -0.006067  0.003253  0.000560  0.000613\n",
      "1  2025-09-01  0.003915  0.015933 -0.006439  0.005382  0.004313  0.000263\n",
      "2  2025-08-01  0.003915  0.013544 -0.007526  0.001882  0.001311  0.000263\n",
      "3  2025-07-01  0.003915  0.014384 -0.008677  0.004882 -0.000921  0.000263\n",
      "4  2025-06-01 -0.017144  0.010090  0.005644  0.017286  0.002249 -0.000699\n",
      "5  2025-05-01 -0.017144  0.009557  0.004335  0.018286  0.001600 -0.000699\n",
      "6  2025-04-01 -0.017144  0.008801  0.005117  0.020286  0.003941 -0.000699\n",
      "7  2025-03-01 -0.012181 -0.008330  0.002249  0.019523  0.004341  0.004022\n",
      "8  2025-02-01 -0.012181 -0.007199  0.001544  0.019523  0.004336  0.004022\n",
      "9  2025-01-01 -0.012181 -0.007718  0.001376  0.024023  0.004364  0.004022\n",
      "10 2024-12-01 -0.016273 -0.015126  0.002012  0.007721  0.003233  0.001534\n",
      "11 2024-11-01 -0.016273 -0.015141  0.003891  0.003221  0.004899  0.001534\n",
      "12 2024-10-01 -0.016273 -0.019988  0.002103 -0.002279  0.001200  0.001534\n",
      "13 2024-09-01 -0.025653 -0.030322  0.002739 -0.004831 -0.008512  0.000515\n",
      "14 2024-08-01 -0.025653 -0.027243  0.004328 -0.003331 -0.010970  0.000515\n"
     ]
    }
   ],
   "source": [
    "# 1) Work on copies\n",
    "gdp = GDPforecast.copy()\n",
    "inf = INFforecast.copy()\n",
    "\n",
    "# 2) Ensure Date is datetime and sorted ascending\n",
    "gdp[\"Date\"] = pd.to_datetime(gdp[\"Date\"])\n",
    "inf[\"Date\"] = pd.to_datetime(inf[\"Date\"])\n",
    "\n",
    "gdp = gdp.sort_values(\"Date\")\n",
    "inf = inf.sort_values(\"Date\")\n",
    "\n",
    "# 3) Align on common dates (inner join on Date)\n",
    "gdp = gdp.set_index(\"Date\")\n",
    "inf = inf.set_index(\"Date\")\n",
    "\n",
    "common_dates = gdp.index.intersection(inf.index)\n",
    "\n",
    "gdp = gdp.loc[common_dates].sort_index()\n",
    "inf = inf.loc[common_dates].sort_index()\n",
    "\n",
    "# 4) Regions we care about\n",
    "regions = [\"AU\", \"GB\", \"CH\", \"JP\", \"EU\", \"US\"]\n",
    "\n",
    "# 5) 12-month changes (Œî) in forecasts\n",
    "gdp_change = gdp[regions].diff(12)   # ŒîGDP_t = GDP_t ‚àí GDP_{t‚àí12}\n",
    "inf_change = inf[regions].diff(12)   # ŒîINF_t = INF_t ‚àí INF_{t‚àí12}\n",
    "\n",
    "# 6) Brooks Business Cycle signal:\n",
    "#    BC = 0.5 * ŒîGDP ‚àí 0.5 * ŒîINF\n",
    "bc_values = 0.5 * gdp_change + 0.5 * inf_change\n",
    "\n",
    "# 7) Build final table with Date as a column\n",
    "bc_signal = bc_values.reset_index()   # Date becomes a column again\n",
    "\n",
    "# Optionally save\n",
    "bc_signal.to_csv(\n",
    "    r\"C:/Users/Sedl√°ƒçek/Documents/UZH/PMP/Macro_momentum/PMP_December_8/Data/BusinessCycle_Signal.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "bc_signal = bc_signal.sort_values(\"Date\", ascending=False).reset_index(drop=True)\n",
    "print(bc_signal.head(15))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
